---
title: "Profanity Detection"
description: "This method helps safeguard your website or app by detecting offensive or inappropriate language in user inputs. By screening for profanity and other harmful content before itâ€™s made public, you can maintain a positive user environment, protect your brand, and prevent abusive behavior on your platform."
api: "GET /scoring/profanity"
---

### Query Parameters

<ParamField
  query="text"
  type="string"
  placeholder="The text"
  required
>
  The text you want to filter

Sample value: `This is a sample text without profanity!`

</ParamField>

<ParamField
  query="scoreOnly"
  type="string"
  default="no"
  placeholder="The value"
>
  Returns only the score of the text and whether it's safe or not.

Expected values: `yes`, or `no`.

</ParamField>

<ParamField
  query="listBadWords"
  type="string"
  default="no"
  placeholder="The value"
>
  Used to list the bad words in an array.

Expected values: `yes`, or `no`.

</ParamField>

<ParamField
  query="format"
  type="string"
  default="JSON"
  placeholder="Response format"
>
  The format command is used to get a response in a specific format.

Expected values: `JSON`, `XML`, or `CSV`

For more information please refer to [Response Format](/options/response-format).

</ParamField>

<ParamField
  query="mode"
  type="string"
  default="live"
  placeholder="Environment"
>
  The mode command is used to in the development stage to simulate the integration process before releasing it to the production environment.

Expected values: `live`, or `test`.

For more information please refer to [Development Environment](/options/development-environment).

</ParamField>

<ParamField
  query="callback"
  type="string"
  placeholder="JSONP callback"
>
  The callback command can help you make the response as a JSONP format.

Expected values: any name that can be used as a function name in Javascript, e.g: `myFunctionName`.

For more information please refer to [JSONP Callback](/options/jsonp-callback).

</ParamField>

<Note>
This method returns a score for the text you pass.

We classify profanity into 4 different level. The first level contains the most risky words and phrases (risky). The second level contains the medium-risk words and phrases. Whereas, the third level contains the low-risk words.

When you use the API, the response will the determine the score of the text you passed as follows:

- `riskScore = 0` means that this text is completely safe.
- `riskScode = 1` means that this is a high-risk text.
- `riskScode = 2` means that this is a medium-risk text.
- `riskScode = 3` means that this is a low-risk text.

</Note>
